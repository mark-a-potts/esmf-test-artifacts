 seqIndexOffset=        1099511627776
 seqIndexOffset=        1099511627776
 seqIndexOffset=        1099511627776
 seqIndexOffset=        1099511627776
--------------------------------------------------------------------------
WARNING: Open MPI will create a shared memory backing file in a
directory that appears to be mounted on a network filesystem.
Creating the shared memory backup file on a network file system, such
as NFS or Lustre is not recommended -- it may cause excessive network
traffic to your file servers and/or cause shared memory traffic in
Open MPI to be much slower than expected.

You may want to check what the typical temporary directory is on your
node.  Possible sources of the location of this temporary directory
include the $TEMPDIR, $TEMP, and $TMP environment variables.

Note, too, that system administrators can set a list of filesystems
where Open MPI is disallowed from creating temporary files by setting
the MCA parameter "orte_no_session_dir".

  Local host: r1i1n34
  Filename:   /p/work1/tmp/mpotts/openmpi-sessions-10547@r1i1n34_0/33827/1/2/vader_segment.r1i1n34.2

You can set the MCA paramter shmem_mmap_enable_nfs_warning to 0 to
disable this message.
--------------------------------------------------------------------------
--- ESMCI::DistGrid::print start ---
indexTK: Integer*8
dimCount = 1
tileCount = 1
elementCountPTile: 20 
regDecomp = NO
--- ESMCI::DistGrid::print start ---
indexTK: Integer*8
dimCount = 1
tileCount = 1
elementCountPTile: 20 
regDecomp = NO
tileListPDe: 1 1 1 1 
elementCountPDe: 5 5 5 5 
--- ESMCI::DistGrid::print start ---
indexTK: Integer*8
dimCount = 1
tileCount = 1
elementCountPTile: 20 
regDecomp = NO
tileListPDe: 1 1 1 1 
elementCountPDe: 5 5 5 5 
contigFlagPDimPDe (dims separated by / ):
 for DE 0: 1 / 
 for DE 1: 1 / 
 for DE 2: 1 / 
 for DE 3: 1 / 
--- ESMCI::DistGrid::print start ---
indexTK: Integer*8
dimCount = 1
tileCount = 1
elementCountPTile: 20 
regDecomp = NO
tileListPDe: 1 1 1 1 
elementCountPDe: 5 5 5 5 
contigFlagPDimPDe (dims separated by / ):
 for DE 0: 1 / 
 for DE 1: 1 / 
 for DE 2: 1 / 
 for DE 3: 1 / 
(min,max)IndexPDimPDe (dims separated by / ):
 for DE 0: (1, 5) / 
tileListPDe: 1 1 1 1 
elementCountPDe: 5 5 5 5 
contigFlagPDimPDe (dims separated by / ):
 for DE 0: 1 / 
 for DE 1: 1 / 
 for DE 2: 1 / 
 for DE 3: 1 / 
(min,max)IndexPDimPDe (dims separated by / ):
 for DE 0: (1, 5) / 
 for DE 1: (6, 10) / 
 for DE 2: (11, 15) / 
 for DE 3: (16, 20) / 
indexListPDimPLocalDe (dims separated by / ):
 for localDE 0 - DE 0:  (1, 2, 3, 4, 5) /
diffCollocationCount = 1
collocationPDim:	1
arbSeqIndexListPCollPLocalDe:
 for collocation 1, localDE 0 - DE 0 -  elementCountPCollPLocalDe 5: (1, 5, 9, 13, 17)
connectionCount = 0
contigFlagPDimPDe (dims separated by / ):
 for DE 0: 1 / 
 for DE 1: 1 / 
 for DE 2: 1 / 
 for DE 3: 1 / 
(min,max)IndexPDimPDe (dims separated by / ):
 for DE 0: (1, 5) / 
 for DE 1: (6, 10) / 
 for DE 2: (11, 15) / 
 for DE 3: (16, 20) / 
indexListPDimPLocalDe (dims separated by / ):
 for localDE 0 - DE 1:  (6, 7, 8, 9, 10) /
diffCollocationCount = 1
collocationPDim:	1
arbSeqIndexListPCollPLocalDe:
 for collocation 1, localDE 0 - DE 1 -  elementCountPCollPLocalDe 5: (2, 6, 10, 14, 18)
connectionCount = 0
~ lower class' values ~
deCount = 4
Member on this PET appears to be an actual member.
DistGrid-VM: localPet = 1, CurrentVM: localPet = 1
DistGrid-VM: petCount = 4, CurrentVM: petCount = 4
--- ESMCI::DistGrid::print end ---
(min,max)IndexPDimPDe (dims separated by / ):
 for DE 0: (1, 5) / 
 for DE 1: (6, 10) / 
 for DE 2: (11, 15) / 
 for DE 3: (16, 20) / 
indexListPDimPLocalDe (dims separated by / ):
 for localDE 0 - DE 2:  (11, 12, 13, 14, 15) /
diffCollocationCount = 1
collocationPDim:	1
arbSeqIndexListPCollPLocalDe:
 for collocation 1, localDE 0 - DE 2 -  elementCountPCollPLocalDe 5: (3, 7, 11, 15, 19)
connectionCount = 0
~ lower class' values ~
deCount = 4
Member on this PET appears to be an actual member.
DistGrid-VM: localPet = 2, CurrentVM: localPet = 2
DistGrid-VM: petCount = 4, CurrentVM: petCount = 4
--- ESMCI::DistGrid::print end ---
 for DE 1: (6, 10) / 
 for DE 2: (11, 15) / 
 for DE 3: (16, 20) / 
indexListPDimPLocalDe (dims separated by / ):
 for localDE 0 - DE 3:  (16, 17, 18, 19, 20) /
diffCollocationCount = 1
collocationPDim:	1
arbSeqIndexListPCollPLocalDe:
 for collocation 1, localDE 0 - DE 3 -  elementCountPCollPLocalDe 5: (4, 8, 12, 16, 20)
connectionCount = 0
~ lower class' values ~
deCount = 4
Member on this PET appears to be an actual member.
DistGrid-VM: localPet = 3, CurrentVM: localPet = 3
DistGrid-VM: petCount = 4, CurrentVM: petCount = 4
--- ESMCI::DistGrid::print end ---
~ lower class' values ~
deCount = 4
Member on this PET appears to be an actual member.
DistGrid-VM: localPet = 0, CurrentVM: localPet = 0
DistGrid-VM: petCount = 4, CurrentVM: petCount = 4
--- ESMCI::DistGrid::print end ---
 farrayPtr1d:    1099511627779.0000        1099511627783.0000        1099511627787.0000        1099511627791.0000        1099511627795.0000        0.0000000000000000        0.0000000000000000        0.0000000000000000     
 farrayPtr1d:    1099511627780.0000        1099511627784.0000        1099511627788.0000        1099511627792.0000        1099511627796.0000        0.0000000000000000        0.0000000000000000        0.0000000000000000        0.0000000000000000     
 farrayPtr1d:    1099511627778.0000        1099511627782.0000        1099511627786.0000        1099511627790.0000        1099511627794.0000        0.0000000000000000        0.0000000000000000     
 farrayPtr1d:    1099511627777.0000        1099511627781.0000        1099511627785.0000        1099511627789.0000        1099511627793.0000        0.0000000000000000     
 farrayPtr1d:    1099511627778.0000        1099511627782.0000        1099511627786.0000        1099511627790.0000        1099511627794.0000        1099511627777.0000        1099511627795.0000     
 farrayPtr1d:    1099511627779.0000        1099511627783.0000        1099511627787.0000        1099511627791.0000        1099511627795.0000        1099511627792.0000        1099511627782.0000        1099511627785.0000     
 farrayPtr1d:    1099511627780.0000        1099511627784.0000        1099511627788.0000        1099511627792.0000        1099511627796.0000        1099511627777.0000        1099511627779.0000        1099511627777.0000        1099511627780.0000     
 farrayPtr1d:    1099511627777.0000        1099511627781.0000        1099511627785.0000        1099511627789.0000        1099511627793.0000        1099511627782.0000     
  PASS  Example ESMF_ArrayArbHaloEx, ESMF_ArrayArbHaloEx.F90, line 650
  PASS  Example ESMF_ArrayArbHaloEx, ESMF_ArrayArbHaloEx.F90, line 650
  PASS  Example ESMF_ArrayArbHaloEx, ESMF_ArrayArbHaloEx.F90, line 650
  PASS  Example ESMF_ArrayArbHaloEx, ESMF_ArrayArbHaloEx.F90, line 650
 PASS: ESMF_ArrayArbHaloEx.F90
 PASS: ESMF_ArrayArbHaloEx.F90
 PASS: ESMF_ArrayArbHaloEx.F90
 PASS: ESMF_ArrayArbHaloEx.F90
[r1i1n34:103670] 5 more processes have sent help message help-opal-shmem-mmap.txt / mmap on nfs
[r1i1n34:103670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
